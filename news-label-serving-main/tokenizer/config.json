{
    "unk_token": {
        "content": "<|endoftext|>",
        "single_word": false,
        "lstrip": false,
        "rstrip": false,
        "normalized": true,
        "__type": "AddedToken"
    },
    "bos_token": {
        "content": "<|endoftext|>",
        "single_word": false,
        "lstrip": false,
        "rstrip": false,
        "normalized": true,
        "__type": "AddedToken"
    },
    "eos_token": {
        "content": "<|endoftext|>",
        "single_word": false,
        "lstrip": false,
        "rstrip": false,
        "normalized": true,
        "__type": "AddedToken"
    },
    "add_prefix_space": false,
    "special_tokens_map_file": null,
    "name_or_path": "temp",
    "errors": "replace",
    "tokenizer_class": "GPT2Tokenizer",
    "model_type": "gpt2"
}